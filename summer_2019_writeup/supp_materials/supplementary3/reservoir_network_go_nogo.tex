
    




    
\documentclass[11pt]{article}

    
    \usepackage[breakable]{tcolorbox}
    \tcbset{nobeforeafter} % prevents tcolorboxes being placing in paragraphs
    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{Reservoir Network Single Output (Go vs. No-Go) \\ Supplementary Material 3}

    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb. 
    \makeatletter
        \newbox\Wrappedcontinuationbox 
        \newbox\Wrappedvisiblespacebox 
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}} 
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}} 
        \newcommand*\Wrappedcontinuationindent {3ex } 
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox} 
        % Take advantage of the already applied Pygments mark-up to insert 
        % potential linebreaks for TeX processing. 
        %        {, <, #, %, $, ' and ": go to next line. 
        %        _, }, ^, &, >, - and ~: stay at end of broken line. 
        % Use of \textquotesingle for straight quote. 
        \newcommand*\Wrappedbreaksatspecials {% 
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}% 
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}% 
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}% 
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}% 
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}% 
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}% 
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}% 
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}% 
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}% 
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}% 
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}% 
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}% 
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}% 
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}% 
        } 
        % Some characters . , ; ? ! / are not pygmentized. 
        % This macro makes them "active" and they will insert potential linebreaks 
        \newcommand*\Wrappedbreaksatpunct {% 
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}% 
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}% 
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}% 
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}% 
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}% 
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}% 
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}% 
            \catcode`\.\active
            \catcode`\,\active 
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active 
            \lccode`\~`\~ 	
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%
        
        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active 	
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}
    
    % prompt
    \newcommand{\prompt}[4]{
        \llap{{\color{#2}[#3]: #4}}\vspace{-1.25em}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \hypertarget{simple-mouse-model}{%
\section{Simple Mouse Model}\label{simple-mouse-model}}

This is a reservoir (1 hidden layer, recurrent) neural network that uses
a form of Hebbian learning on the final set of weights between the
hidden layer and the output in order to recreate the initial learning
behaviour of mice during tactile discrimination.

\hypertarget{people}{%
\subsection{People:}\label{people}}

Abhi, Aleksej, Hector,

\hypertarget{expected-results}{%
\subsection{Expected Results}\label{expected-results}}

With sufficient hidden nodes, the neural network should exhibit the same
learning behavior (similar speed and accuracy) as mice during their
Learning Naive and Learning Expert phases.

I do not expect the model to be capable of emulating mice behavior
during the reversal learning phases; more specifically, Reversal
Learning and Reversal Expert phases. \textbf{If the model is
sufficiently close to biological plausibility and behaviour, it should
exhibit the learning behavior of mice whose OFC has been ablated.}

\hypertarget{previous-work}{%
\subsection{Previous Work}\label{previous-work}}

In a previous notebook, I have implemented the work of Zhang, et.
al.~published in early 2018
\href{https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1005925\&type=printable}{A
neural network model for the orbitofrontal cortex and task space
acquisition during reinforcement learning}. I observed that the model
began to learn only when changing the sign of the originally stipulated
weight update. Removing the reward input also improved the learning
performance of the model.

\hypertarget{goals}{%
\subsection{Goals}\label{goals}}

The biggest issue with the modified implementation of the OFC reservoir
network is the violation of the experimental paradigm. As mice are
trained, they are dehydrated, which means that naive mice are
predisposed to always lick any water spout. Mice must therefore learn
\textbf{not to lick}. Biologically, it is observed that the neural
pathways that dictate go and no-go actions are separate. In order to
observe this peculiarity, I will reduce the model to have one single
output.

\hypertarget{the-reservoir-neural-network-model}{%
\subsection{The Reservoir Neural Network
Model}\label{the-reservoir-neural-network-model}}

\hypertarget{mathematics}{%
\subsubsection{Mathematics}\label{mathematics}}

Below are the mathematical formulations I used directly in the
implementation of the reservoir neural network described in the paper;
including my changes for improved performance. These have once more been
adapted to describe a model that only contains one output.

The network has N nodes whose activation value \(x\) is represented by
\begin{align}
\frac{1}{\tau} \frac{dx}{dt}= -x_i + g \sum_{j=1}^N w_{ij} y_j + w_i^{(i)}I + \sigma_{noise}dW_i \\
x(t + 1) = x(t) + \dot{x}(t)\Delta t
\end{align}

Where \(dW_i\) stands for white noise sampled from a uniform
distribution {[}0, 1{]} and \(\sigma_{noise}\) is its variance. \(y_i\)
is the firing rate of neuron \(i\), relative to a \(y_{min}=0\),
\(y_{max}=1\) and baseline firing rate \(y_0 = 0.1\). It is determined
by the following piecewise function: \begin{align}
y=   \left\{
\begin{array}{ll}
      y_0 + y_0 tanh(x/y_0) & x \leq 0   \\
      y_0 + (y_{max} - y_0)*tanh(\frac{x}{y_{max}- y_0}) & x > 0 \\
\end{array} 
\right.
\end{align}

The contributions of each node are then summed to \(v\). \(p\) is then
determined by applying the sigmoid function on \(v\). \(p\) then becomes
the expected reward \(E[r]\) \begin{align}
v = \sum_{i=1}^N w_{out} * y_i \\
p = E[r] = \frac{1}{1 + e^{v}}
\end{align}

The final output elements \(z\) is either 1 with probability \(p\) or 0
with probability \(1 - p\) The weighted random choice should be biased
towards an output of 1 (i.e.~to lick) upon initialization and then
slowly decrease. This may require that the weights not be normalized or
that they always be positive. This, I will explore a bit later.

The weights on the output layer (\(w_{out}\)) are the only ones that are
plastic. These are only updated on the same timestep that the reward
\(r\) is administered because the mice do not receive any information
nor feedback when they refuse to lick, regardless of the texture
presented: \begin{align}
\Delta w_{out} = \eta (r - E[r]) (y_i - y_{th}) z_k \\
w_{out}(n + 1) = w_{out}(n) - \Delta w_{out} \\
\end{align} Finally, the weights are normalized after each update:
\begin{align}
w_{out}(n) = \frac{w_{out}(n)}{\sqrt{\sum_{i=1}^N ||w_{out}(n)||^2}}
\end{align}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{13}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
\PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt} 
\PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{signal} \PY{k}{import} \PY{n}{butter}\PY{p}{,} \PY{n}{lfilter}\PY{p}{,} \PY{n}{freqz}
\PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sns}
\PY{n}{sns}\PY{o}{.}\PY{n}{set}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{14}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Model parameters.}
\PY{n}{num\PYZus{}trials} \PY{o}{=} \PY{l+m+mi}{3000} \PY{c+c1}{\PYZsh{} Original number: 1000}
\PY{n}{StopTrainingTrials} \PY{o}{=} \PY{l+m+mi}{5000}
\PY{n}{numReversed} \PY{o}{=} \PY{l+m+mi}{100}
\PY{n}{reinforcedSchedule} \PY{o}{=} \PY{l+m+mi}{1} \PY{c+c1}{\PYZsh{} determined or prob}
\PY{n}{withRF} \PY{o}{=} \PY{l+m+mi}{1}  \PY{c+c1}{\PYZsh{} reward feedback}
\PY{n}{numMod} \PY{o}{=} \PY{l+m+mi}{1}
\PY{n}{detail} \PY{o}{=} \PY{l+m+mi}{0}
\PY{n}{REinitial} \PY{o}{=} \PY{l+m+mi}{1}
\PY{n}{simutan}\PY{o}{=} \PY{l+m+mi}{1}
\PY{n}{blocking} \PY{o}{=} \PY{l+m+mi}{0} \PY{c+c1}{\PYZsh{} 0:no block, 1: random block,  2:A block,  3: AR block }

\PY{c+c1}{\PYZsh{} set the time}
\PY{n}{dt} \PY{o}{=} \PY{l+m+mf}{0.001}
\PY{n}{start} \PY{o}{=} \PY{l+m+mf}{0.2}    \PY{c+c1}{\PYZsh{} upon time of stimulus}
\PY{n}{sdur} \PY{o}{=} \PY{l+m+mf}{0.5}    \PY{c+c1}{\PYZsh{} duration of the stimulus}
\PY{n}{inter} \PY{o}{=} \PY{l+m+mi}{0}   \PY{c+c1}{\PYZsh{} interval between stimulus and reward}
\PY{n}{rdur} \PY{o}{=} \PY{l+m+mf}{0.5}    \PY{c+c1}{\PYZsh{} duration of reward input}
\PY{n}{delay} \PY{o}{=} \PY{l+m+mf}{0.2}   \PY{c+c1}{\PYZsh{} delay before decision}
\PY{n}{intertrial} \PY{o}{=} \PY{l+m+mi}{0}
\PY{n}{tau} \PY{o}{=} \PY{l+m+mf}{0.1} \PY{c+c1}{\PYZsh{} time constant }
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{15}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Model parameters from OFC paper for the reversal learning task}
\PY{n}{reservoir\PYZus{}network\PYZus{}params} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tau}\PY{l+s+s1}{\PYZsq{}}         \PY{p}{:} \PY{l+m+mf}{0.1}\PY{p}{,}         \PY{c+c1}{\PYZsh{} 100ms.}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dt}\PY{l+s+s1}{\PYZsq{}}          \PY{p}{:} \PY{l+m+mf}{0.001}\PY{p}{,}       \PY{c+c1}{\PYZsh{} 1ms.}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{network gain}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{2}\PY{p}{,}           \PY{c+c1}{\PYZsh{} g}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{training threshold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.2}\PY{p}{,}   \PY{c+c1}{\PYZsh{} y\PYZus{}th}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{temp parameter}\PY{l+s+s1}{\PYZsq{}}    \PY{p}{:} \PY{l+m+mi}{4}\PY{p}{,}     \PY{c+c1}{\PYZsh{} B (beta)}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{learning rate}\PY{l+s+s1}{\PYZsq{}}     \PY{p}{:} \PY{l+m+mf}{0.001}\PY{p}{,} \PY{c+c1}{\PYZsh{} n (eta)}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max firing rate}\PY{l+s+s1}{\PYZsq{}}   \PY{p}{:} \PY{l+m+mi}{1}\PY{p}{,}     \PY{c+c1}{\PYZsh{} y\PYZus{}max}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{base firing rate}\PY{l+s+s1}{\PYZsq{}}  \PY{p}{:} \PY{l+m+mf}{0.1}\PY{p}{,}   \PY{c+c1}{\PYZsh{} y\PYZus{}0}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{noise gain}\PY{l+s+s1}{\PYZsq{}}  \PY{p}{:} \PY{l+m+mf}{0.01}\PY{p}{,}        \PY{c+c1}{\PYZsh{} sigma\PYZus{}noise}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{initial noise gain}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.01}\PY{p}{,}  \PY{c+c1}{\PYZsh{} sigma\PYZus{}ini}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{input gain}\PY{l+s+s1}{\PYZsq{}}  \PY{p}{:} \PY{l+m+mi}{4}\PY{p}{,}           \PY{c+c1}{\PYZsh{} g\PYZus{}IR        gain input \PYZhy{}\PYZgt{} reservoir}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{input prob}\PY{l+s+s1}{\PYZsq{}}  \PY{p}{:} \PY{l+m+mf}{0.2}\PY{p}{,}         \PY{c+c1}{\PYZsh{} p\PYZus{}IR        prob input \PYZhy{}\PYZgt{} reservoir}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hidden layer prob}\PY{l+s+s1}{\PYZsq{}} \PY{p}{:} \PY{l+m+mf}{0.1}\PY{p}{,}   \PY{c+c1}{\PYZsh{} p           Probability of connection in hidden layer}
\PY{p}{\PYZcb{}}

\PY{c+c1}{\PYZsh{} Model parameters for shallow neural network}
\PY{n}{shallow\PYZus{}network\PYZus{}params} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tau}\PY{l+s+s1}{\PYZsq{}}         \PY{p}{:} \PY{l+m+mf}{0.1}\PY{p}{,}         \PY{c+c1}{\PYZsh{} 100ms.}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dt}\PY{l+s+s1}{\PYZsq{}}          \PY{p}{:} \PY{l+m+mf}{0.001}\PY{p}{,}       \PY{c+c1}{\PYZsh{} 1ms.}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{network gain}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{2}\PY{p}{,}           \PY{c+c1}{\PYZsh{} g}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{training threshold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.2}\PY{p}{,}   \PY{c+c1}{\PYZsh{} y\PYZus{}th}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{temp parameter}\PY{l+s+s1}{\PYZsq{}}    \PY{p}{:} \PY{l+m+mi}{4}\PY{p}{,}     \PY{c+c1}{\PYZsh{} B (beta)}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{learning rate}\PY{l+s+s1}{\PYZsq{}}     \PY{p}{:} \PY{l+m+mf}{0.001}\PY{p}{,} \PY{c+c1}{\PYZsh{} n (eta)}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{noise gain}\PY{l+s+s1}{\PYZsq{}}  \PY{p}{:} \PY{l+m+mf}{0.01}\PY{p}{,}        \PY{c+c1}{\PYZsh{} sigma\PYZus{}noise}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{initial noise gain}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.01}\PY{p}{,}  \PY{c+c1}{\PYZsh{} sigma\PYZus{}ini}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{input gain}\PY{l+s+s1}{\PYZsq{}}  \PY{p}{:} \PY{l+m+mi}{4}\PY{p}{,}           \PY{c+c1}{\PYZsh{} g\PYZus{}IR        gain input \PYZhy{}\PYZgt{} reservoir}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{input prob}\PY{l+s+s1}{\PYZsq{}}  \PY{p}{:} \PY{l+m+mf}{0.2}\PY{p}{,}         \PY{c+c1}{\PYZsh{} p\PYZus{}IR        prob input \PYZhy{}\PYZgt{} reservoir}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hidden layer prob}\PY{l+s+s1}{\PYZsq{}} \PY{p}{:} \PY{l+m+mf}{0.1}\PY{p}{,}   \PY{c+c1}{\PYZsh{} p           Probability of connection in hidden layer}
\PY{p}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{16}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Activation/Threshold functions.}
\PY{k}{def} \PY{n+nf}{ReLU}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{p}{:}
  \PY{k}{return} \PY{n}{x} \PY{o}{*} \PY{p}{(}\PY{n}{x} \PY{o}{\PYZgt{}} \PY{l+m+mi}{0}\PY{p}{)}

\PY{k}{def} \PY{n+nf}{sigmoid}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{derivative}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{:}
  \PY{k}{return} \PY{n}{x}\PY{o}{*}\PY{p}{(}\PY{l+m+mi}{1}\PY{o}{\PYZhy{}}\PY{n}{x}\PY{p}{)} \PY{k}{if} \PY{n}{derivative} \PY{k}{else} \PY{l+m+mi}{1}\PY{o}{/}\PY{p}{(}\PY{l+m+mi}{1}\PY{o}{+}\PY{n}{np}\PY{o}{.}\PY{n}{exp}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{n}{x}\PY{p}{)}\PY{p}{)}

\PY{k}{def} \PY{n+nf}{sigmoid\PYZus{}avg}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{x0}\PY{p}{,} \PY{n}{derivative}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{:}
  \PY{k}{return} \PY{n}{x}\PY{o}{*}\PY{p}{(}\PY{l+m+mi}{1}\PY{o}{\PYZhy{}}\PY{n}{x}\PY{o}{/}\PY{n}{x0}\PY{p}{)} \PY{k}{if} \PY{n}{derivative} \PY{k}{else} \PY{l+m+mi}{1}\PY{o}{/}\PY{p}{(}\PY{l+m+mi}{1}\PY{o}{+}\PY{n}{np}\PY{o}{.}\PY{n}{exp}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{n}{x}\PY{o}{/}\PY{n}{x0}\PY{p}{)}\PY{p}{)}

\PY{k}{def} \PY{n+nf}{softmax}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{beta}\PY{p}{)}\PY{p}{:}
  \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{exp}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{n}{beta} \PY{o}{*} \PY{n}{x}\PY{p}{)} \PY{o}{/} \PY{n}{np}\PY{o}{.}\PY{n}{exp}\PY{p}{(}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{n}{beta} \PY{o}{*} \PY{n}{x}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Filter functions.}
\PY{k}{def} \PY{n+nf}{butter\PYZus{}lowpass}\PY{p}{(}\PY{n}{cutoff}\PY{p}{,} \PY{n}{fs}\PY{p}{,} \PY{n}{order}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{:}
    \PY{n}{nyq} \PY{o}{=} \PY{l+m+mf}{0.5} \PY{o}{*} \PY{n}{fs}
    \PY{n}{normal\PYZus{}cutoff} \PY{o}{=} \PY{n}{cutoff} \PY{o}{/} \PY{n}{nyq}
    \PY{n}{b}\PY{p}{,} \PY{n}{a} \PY{o}{=} \PY{n}{butter}\PY{p}{(}\PY{n}{order}\PY{p}{,} \PY{n}{normal\PYZus{}cutoff}\PY{p}{,} \PY{n}{btype}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{low}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{analog}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
    \PY{k}{return} \PY{n}{b}\PY{p}{,} \PY{n}{a}

\PY{k}{def} \PY{n+nf}{butter\PYZus{}lowpass\PYZus{}filter}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{cutoff}\PY{p}{,} \PY{n}{fs}\PY{p}{,} \PY{n}{order}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{:}
    \PY{n}{b}\PY{p}{,} \PY{n}{a} \PY{o}{=} \PY{n}{butter\PYZus{}lowpass}\PY{p}{(}\PY{n}{cutoff}\PY{p}{,} \PY{n}{fs}\PY{p}{,} \PY{n}{order}\PY{o}{=}\PY{n}{order}\PY{p}{)}
    \PY{n}{y} \PY{o}{=} \PY{n}{lfilter}\PY{p}{(}\PY{n}{b}\PY{p}{,} \PY{n}{a}\PY{p}{,} \PY{n}{data}\PY{p}{)}
    \PY{k}{return} \PY{n}{y}
  
\PY{k}{def} \PY{n+nf}{gaussian}\PY{p}{(}\PY{n}{mu}\PY{p}{,}\PY{n}{s2}\PY{p}{)}\PY{p}{:}
    \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{exp}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{n}{mu}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2}\PY{o}{/}\PY{l+m+mi}{2}\PY{o}{/}\PY{n}{s2}\PY{p}{)} \PY{o}{/} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{l+m+mi}{2} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{pi} \PY{o}{*} \PY{n}{s2}\PY{p}{)}

\PY{k}{def} \PY{n+nf}{smooth}\PY{p}{(}\PY{n}{x1}\PY{p}{,} \PY{n}{x2}\PY{p}{,} \PY{n}{y1}\PY{p}{,} \PY{n}{s2}\PY{p}{)}\PY{p}{:}
    \PY{n}{N2} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x2}\PY{p}{)}
    \PY{n}{y2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n}{N2}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Check that the new data range does not exceed the old one}
    \PY{n}{rangeX1} \PY{o}{=} \PY{p}{[}\PY{n}{np}\PY{o}{.}\PY{n}{min}\PY{p}{(}\PY{n}{x1}\PY{p}{)}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{n}{x1}\PY{p}{)}\PY{p}{]}
    \PY{n}{rangeX2} \PY{o}{=} \PY{p}{[}\PY{n}{np}\PY{o}{.}\PY{n}{min}\PY{p}{(}\PY{n}{x2}\PY{p}{)}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{n}{x2}\PY{p}{)}\PY{p}{]}

    \PY{k}{for} \PY{n}{i2} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{x2}\PY{o}{.}\PY{n}{size}\PY{p}{)}\PY{p}{:}
        \PY{n}{w\PYZus{}ker} \PY{o}{=} \PY{n}{gaussian}\PY{p}{(}\PY{n}{x2}\PY{p}{[}\PY{n}{i2}\PY{p}{]} \PY{o}{\PYZhy{}} \PY{n}{x1}\PY{p}{,} \PY{n}{s2}\PY{p}{)}
        \PY{n}{w\PYZus{}ker} \PY{o}{/}\PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{w\PYZus{}ker}\PY{p}{)}
        \PY{n}{y2}\PY{p}{[}\PY{n}{i2}\PY{p}{]} \PY{o}{=} \PY{n}{w\PYZus{}ker}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{y1}\PY{p}{)}

    \PY{k}{return} \PY{n}{y2}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{17}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Custom neural network class.}

\PY{k}{class} \PY{n+nc}{SpikingReservoir\PYZus{}v1}\PY{p}{(}\PY{n+nb}{object}\PY{p}{)}\PY{p}{:}
  \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{nodes}\PY{p}{,} \PY{n}{input\PYZus{}dim}\PY{p}{,} \PY{n}{params}\PY{p}{,} \PY{n}{output\PYZus{}dim}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{sparse}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{:}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{sparse} \PY{o}{=} \PY{n}{sparse}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{output\PYZus{}dim} \PY{o}{=} \PY{n}{output\PYZus{}dim}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params} \PY{o}{=} \PY{n}{params}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{init\PYZus{}input\PYZus{}weights}\PY{p}{(}\PY{n}{input\PYZus{}dim}\PY{p}{,} \PY{n}{nodes}\PY{p}{)}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{init\PYZus{}hidden\PYZus{}weights}\PY{p}{(}\PY{n}{nodes}\PY{p}{)}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{init\PYZus{}neurons}\PY{p}{(}\PY{n}{nodes}\PY{p}{)}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{init\PYZus{}output\PYZus{}weights}\PY{p}{(}\PY{n}{nodes}\PY{p}{,} \PY{n}{output\PYZus{}dim}\PY{p}{)}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{exp\PYZus{}r} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n}{output\PYZus{}dim}\PY{p}{)}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{z} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n}{output\PYZus{}dim}\PY{p}{)}

  \PY{k}{def} \PY{n+nf}{init\PYZus{}input\PYZus{}weights}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{input\PYZus{}dim}\PY{p}{,} \PY{n}{nodes}\PY{p}{)}\PY{p}{:}
    \PY{n}{std\PYZus{}dev} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{input gain}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}  \PY{c+c1}{\PYZsh{} The paper uses a variance of g\PYZus{}IR\PYZca{}2}
    \PY{n}{w\PYZus{}input} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{std\PYZus{}dev}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{p}{(}\PY{n}{input\PYZus{}dim}\PY{p}{,} \PY{n}{nodes}\PY{p}{)}\PY{p}{)}
    \PY{k}{if} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{sparse}\PY{p}{:}
      \PY{n}{p\PYZus{}IR} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{input prob}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
      \PY{n}{indices} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n}{w\PYZus{}input}\PY{o}{.}\PY{n}{shape}\PY{p}{,} \PY{n}{p}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{p\PYZus{}IR}\PY{p}{,} \PY{n}{p\PYZus{}IR}\PY{p}{]}\PY{p}{)} 
      \PY{n}{w\PYZus{}input} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{multiply}\PY{p}{(}\PY{n}{w\PYZus{}input}\PY{p}{,} \PY{n}{indices}\PY{p}{)}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}input} \PY{o}{=} \PY{n}{w\PYZus{}input}
      
  \PY{k}{def} \PY{n+nf}{init\PYZus{}hidden\PYZus{}weights}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{nodes}\PY{p}{)}\PY{p}{:}
    \PY{n}{g} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{initial noise gain}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
    \PY{n}{p} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hidden layer prob}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
    \PY{n}{std\PYZus{}dev} \PY{o}{=} \PY{n}{g} \PY{o}{/} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n}{p} \PY{o}{*} \PY{n}{nodes}\PY{p}{)} \PY{c+c1}{\PYZsh{} The paper uses a variance of g\PYZca{}2/(p*N)}
    \PY{n}{W} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{std\PYZus{}dev}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{p}{(}\PY{n}{nodes}\PY{p}{,} \PY{n}{nodes}\PY{p}{)}\PY{p}{)}
    \PY{k}{if} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{sparse}\PY{p}{:}
      \PY{n}{indices} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n}{W}\PY{o}{.}\PY{n}{shape}\PY{p}{,} \PY{n}{p}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{p}\PY{p}{,} \PY{n}{p}\PY{p}{]}\PY{p}{)}
      \PY{n}{W} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{multiply}\PY{p}{(}\PY{n}{W}\PY{p}{,} \PY{n}{indices}\PY{p}{)}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{hidden\PYZus{}weights} \PY{o}{=} \PY{n}{W}
    
  \PY{k}{def} \PY{n+nf}{init\PYZus{}neurons}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{nodes}\PY{p}{)}\PY{p}{:}
    \PY{n}{std\PYZus{}dev} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{initial noise gain}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{c+c1}{\PYZsh{} The paper uses a variance of sigma\PYZus{}ini\PYZca{}2}
    \PY{n}{x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{std\PYZus{}dev}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n}{nodes}\PY{p}{)}
    \PY{n}{y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{ones}\PY{p}{(}\PY{n}{nodes}\PY{p}{)} \PY{o}{*} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{base firing rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x} \PY{o}{=} \PY{n}{x}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{y} \PY{o}{=} \PY{n}{y}
    
  \PY{k}{def} \PY{n+nf}{init\PYZus{}output\PYZus{}weights}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{nodes}\PY{p}{,} \PY{n}{output\PYZus{}dim}\PY{p}{)}\PY{p}{:}
    \PY{n}{W} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{p}{(}\PY{n}{nodes}\PY{p}{,} \PY{n}{output\PYZus{}dim}\PY{p}{)}\PY{p}{)}
    \PY{c+c1}{\PYZsh{} According to the paper: normalize according to the squared sum of the weights for each output node.}
    \PY{n}{W} \PY{o}{=} \PY{n}{W}\PY{o}{/}\PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{square}\PY{p}{(}\PY{n}{W}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{output\PYZus{}weights} \PY{o}{=} \PY{n}{W}

  \PY{k}{def} \PY{n+nf}{step}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{I}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}\PY{p}{:}
    \PY{k}{if} \PY{n}{np}\PY{o}{.}\PY{n}{array\PYZus{}equal}\PY{p}{(}\PY{n}{I}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{:}
        \PY{n}{I} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}input}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}

    \PY{n}{tau} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tau}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
    \PY{n}{dt} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
    \PY{n}{g} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{network gain}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
    \PY{n}{sigma\PYZus{}noise} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{noise gain}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
    \PY{n}{y\PYZus{}0} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{base firing rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
    \PY{n}{y\PYZus{}max} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max firing rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}

    \PY{n}{white\PYZus{}noise} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{randint}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{high}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x}\PY{o}{.}\PY{n}{size}\PY{p}{)}

    \PY{n}{dx\PYZus{}dt} \PY{o}{=} \PY{l+m+mi}{1}\PY{o}{/}\PY{n}{tau} \PY{o}{*} \PY{p}{(}\PY{o}{\PYZhy{}}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x} \PY{o}{+} \PY{n}{g} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{hidden\PYZus{}weights}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{y}\PY{p}{)} 
                     \PY{o}{+} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}input}\PY{o}{.}\PY{n}{T}\PY{p}{,} \PY{n}{I}\PY{p}{)} 
                     \PY{o}{+} \PY{n}{sigma\PYZus{}noise} \PY{o}{*} \PY{n}{white\PYZus{}noise}\PY{p}{)}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x} \PY{o}{+}\PY{o}{=} \PY{n}{dx\PYZus{}dt} \PY{o}{*} \PY{n}{dt}

    \PY{n}{y\PYZus{}conditions} \PY{o}{=}\PY{p}{[}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{l+m+mi}{0}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x} \PY{o}{\PYZgt{}} \PY{l+m+mi}{0}\PY{p}{]}
    \PY{n}{y\PYZus{}functions} \PY{o}{=}\PY{p}{[}
        \PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{y\PYZus{}0} \PY{o}{+} \PY{n}{y\PYZus{}0} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{tanh}\PY{p}{(}\PY{n}{x}\PY{o}{/}\PY{n}{y\PYZus{}0}\PY{p}{)}\PY{p}{,}
        \PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{y\PYZus{}0} \PY{o}{+} \PY{p}{(}\PY{n}{y\PYZus{}max} \PY{o}{\PYZhy{}} \PY{n}{y\PYZus{}0}\PY{p}{)} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{tanh}\PY{p}{(}\PY{n}{x}\PY{o}{/}\PY{p}{(}\PY{n}{y\PYZus{}max} \PY{o}{\PYZhy{}} \PY{n}{y\PYZus{}0}\PY{p}{)}\PY{p}{)}
    \PY{p}{]}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{piecewise}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x}\PY{p}{,} \PY{n}{y\PYZus{}conditions}\PY{p}{,} \PY{n}{y\PYZus{}functions}\PY{p}{)}

    \PY{n}{v} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{y}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{output\PYZus{}weights}\PY{p}{)}
    \PY{n}{p} \PY{o}{=} \PY{n}{sigmoid\PYZus{}avg}\PY{p}{(}\PY{n}{v}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{exp\PYZus{}r} \PY{o}{=} \PY{n}{p}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{z} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{p}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{1}\PY{o}{\PYZhy{}}\PY{n}{p}\PY{p}{,} \PY{n}{p}\PY{p}{]}\PY{p}{)}

    \PY{k}{return} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{z}

  \PY{k}{def} \PY{n+nf}{receive\PYZus{}reward}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{r}\PY{p}{)}\PY{p}{:}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{p}{)}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{update\PYZus{}weights}\PY{p}{(}\PY{n}{r}\PY{p}{)}
  
  \PY{k}{def} \PY{n+nf}{update\PYZus{}weights}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{r}\PY{p}{)}\PY{p}{:}
    \PY{n}{delta\PYZus{}w} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{learning rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{outer}\PY{p}{(}\PY{p}{(}\PY{n}{r} \PY{o}{\PYZhy{}} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{exp\PYZus{}r}\PY{p}{)}\PY{p}{,}
             \PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{y} \PY{o}{\PYZhy{}} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{training threshold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
    \PY{n}{delta\PYZus{}w} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{multiply}\PY{p}{(}\PY{n}{delta\PYZus{}w}\PY{o}{.}\PY{n}{T}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{z}\PY{p}{)}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{output\PYZus{}weights} \PY{o}{+}\PY{o}{=} \PY{n}{delta\PYZus{}w}
    \PY{c+c1}{\PYZsh{}self.output\PYZus{}weights = (self.output\PYZus{}weights + delta\PYZus{}w).clip(min=0)}
    
    \PY{c+c1}{\PYZsh{} Normalize weights}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{output\PYZus{}weights} \PY{o}{/}\PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{norm}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{output\PYZus{}weights}\PY{p}{)}
  
  \PY{k}{def} \PY{n+nf}{get\PYZus{}output}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{exp}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{:}
    \PY{k}{if} \PY{n}{exp}\PY{p}{:}
        \PY{k}{return} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{z}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{exp\PYZus{}r}
    \PY{k}{else}\PY{p}{:}
        \PY{k}{return} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{z}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{18}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Inputs.}
\PY{n}{I\PYZus{}1} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
\PY{n}{I\PYZus{}2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}

\PY{n}{I} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{I\PYZus{}1}\PY{p}{,} \PY{n}{I\PYZus{}2}\PY{p}{]}\PY{p}{)}


\PY{c+c1}{\PYZsh{} Outpus.}
\PY{n}{A\PYZus{}1} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)} \PY{c+c1}{\PYZsh{} Go.}
\PY{n}{A\PYZus{}2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)} \PY{c+c1}{\PYZsh{} No\PYZhy{}go.}


\PY{c+c1}{\PYZsh{} Expected outputs.}
\PY{n}{I2A\PYZus{}1} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{A\PYZus{}1}\PY{p}{,} \PY{n}{A\PYZus{}2}\PY{p}{]}\PY{p}{)}
\PY{n}{I2A\PYZus{}2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{A\PYZus{}2}\PY{p}{,} \PY{n}{A\PYZus{}1}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{19}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{simple\PYZus{}experiment}\PY{p}{(}\PY{n}{T}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{,} \PY{n}{num\PYZus{}trials}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{,} \PY{n}{net}\PY{o}{=}\PY{k+kc}{None}\PY{p}{,}
                      \PY{n}{I}\PY{o}{=}\PY{k+kc}{None}\PY{p}{,} \PY{n}{contingency}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}\PY{p}{:}
  \PY{n}{rew\PYZus{}hist} \PY{o}{=} \PY{p}{[}\PY{p}{]}
  \PY{n}{dec\PYZus{}hist} \PY{o}{=} \PY{p}{[}\PY{p}{]}
  \PY{n}{exp\PYZus{}hist} \PY{o}{=} \PY{p}{[}\PY{p}{]}


  \PY{k}{for} \PY{n}{trial} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{num\PYZus{}trials}\PY{p}{)}\PY{p}{:}
    \PY{n}{index} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{randint}\PY{p}{(}\PY{n}{I}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
    \PY{n}{texture} \PY{o}{=} \PY{n}{I}\PY{p}{[}\PY{n}{index}\PY{p}{]}
    \PY{n}{exp\PYZus{}output} \PY{o}{=} \PY{n}{contingency}\PY{p}{[}\PY{n}{index}\PY{p}{]}

    \PY{n}{decision} \PY{o}{=} \PY{l+m+mi}{0}
    \PY{n}{expectation} \PY{o}{=} \PY{l+m+mi}{0}
    \PY{n}{r} \PY{o}{=} \PY{l+m+mi}{0}
    
    \PY{k}{for} \PY{n}{ms} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{T}\PY{p}{)}\PY{p}{:}

      \PY{c+c1}{\PYZsh{} Initial rest period (0 \PYZhy{} 200ms) of trial}
      \PY{k}{if} \PY{n}{ms} \PY{o}{\PYZlt{}} \PY{p}{(}\PY{n}{T} \PY{o}{*} \PY{n}{delay}\PY{p}{)}\PY{p}{:}
        \PY{n}{net}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{p}{)}
        \PY{k}{continue}

      \PY{c+c1}{\PYZsh{} Apply input for the trial (200ms \PYZhy{} 700ms)}
      \PY{k}{if} \PY{l+m+mi}{200} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{n}{ms} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{l+m+mi}{700}\PY{p}{:}
        \PY{n}{net}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{n}{texture}\PY{p}{)}
        \PY{k}{continue}

      \PY{c+c1}{\PYZsh{} Measure output of the network (900ms)}
      \PY{k}{if} \PY{n}{ms} \PY{o}{==} \PY{l+m+mi}{900}\PY{p}{:}
        \PY{n}{decision}\PY{p}{,} \PY{n}{expectation} \PY{o}{=} \PY{n}{net}\PY{o}{.}\PY{n}{get\PYZus{}output}\PY{p}{(}\PY{n}{exp}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}   
        
        \PY{k}{if} \PY{n}{decision} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{:}
          \PY{n}{r} \PY{o}{=} \PY{l+m+mi}{0}
        \PY{k}{elif} \PY{n}{decision} \PY{o}{==} \PY{n}{exp\PYZus{}output}\PY{p}{:}
          \PY{n}{r} \PY{o}{=} \PY{l+m+mi}{1}
        \PY{k}{else}\PY{p}{:}
          \PY{n}{r} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}

        \PY{n}{net}\PY{o}{.}\PY{n}{receive\PYZus{}reward}\PY{p}{(}\PY{n}{r}\PY{p}{)}
        \PY{k}{continue}

      \PY{c+c1}{\PYZsh{} If nothing needs to happen, move forward a timestep.}
      \PY{n}{net}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{p}{)}

    \PY{n}{rew\PYZus{}hist} \PY{o}{+}\PY{o}{=} \PY{p}{[}\PY{n}{r}\PY{p}{]}
    \PY{n}{dec\PYZus{}hist} \PY{o}{+}\PY{o}{=} \PY{p}{[}\PY{n}{decision}\PY{p}{]}
    \PY{n}{exp\PYZus{}hist} \PY{o}{+}\PY{o}{=} \PY{p}{[}\PY{n}{expectation}\PY{p}{]}
    
  \PY{n}{rew\PYZus{}hist} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{rew\PYZus{}hist}\PY{p}{)}
  \PY{n}{dec\PYZus{}hist} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{dec\PYZus{}hist}\PY{p}{)}
  \PY{n}{exp\PYZus{}hist} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{exp\PYZus{}hist}\PY{p}{)}
  \PY{k}{return} \PY{n}{rew\PYZus{}hist}\PY{p}{,} \PY{n}{dec\PYZus{}hist}\PY{p}{,} \PY{n}{exp\PYZus{}hist}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{20}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Simple experiment:}

\PY{n}{net} \PY{o}{=} \PY{n}{SpikingReservoir\PYZus{}v1}\PY{p}{(}\PY{l+m+mi}{500}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{n}{reservoir\PYZus{}network\PYZus{}params}\PY{p}{)}
\PY{n}{r\PYZus{}hist}\PY{p}{,} \PY{n}{decision\PYZus{}hist}\PY{p}{,} \PY{n}{exp\PYZus{}hist} \PY{o}{=} \PY{n}{simple\PYZus{}experiment}\PY{p}{(}\PY{n}{T}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{,} \PY{n}{num\PYZus{}trials}\PY{o}{=}\PY{l+m+mi}{300}\PY{p}{,} 
                              \PY{n}{net}\PY{o}{=}\PY{n}{net}\PY{p}{,} \PY{n}{I}\PY{o}{=}\PY{n}{I}\PY{p}{,} \PY{n}{contingency}\PY{o}{=}\PY{n}{I2A\PYZus{}1}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{21}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Smoothen the reward history curve.}
\PY{n}{time\PYZus{}filtered} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{r\PYZus{}hist}\PY{o}{.}\PY{n}{size}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}
\PY{n}{r\PYZus{}filtered} \PY{o}{=} \PY{n}{smooth}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{n}{r\PYZus{}hist}\PY{o}{.}\PY{n}{size}\PY{p}{)}\PY{p}{,} \PY{n}{time\PYZus{}filtered}\PY{p}{,} \PY{n}{r\PYZus{}hist}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Calculate TD error history.}
\PY{n}{td\PYZus{}hist} \PY{o}{=} \PY{n}{r\PYZus{}hist} \PY{o}{\PYZhy{}} \PY{n}{np}\PY{o}{.}\PY{n}{multiply}\PY{p}{(}\PY{n}{exp\PYZus{}hist}\PY{p}{,} \PY{n}{decision\PYZus{}hist}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{22}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Plot.}
\PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{nrows} \PY{o}{=} \PY{l+m+mi}{4}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{4}\PY{o}{*}\PY{l+m+mi}{4}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{r\PYZus{}hist}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{time\PYZus{}filtered}\PY{p}{,} \PY{n}{r\PYZus{}filtered}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{decision\PYZus{}hist}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{exp\PYZus{}hist}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{td\PYZus{}hist}\PY{p}{)}

\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{reward applied (+ smoothening)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{decision history}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{expectation history}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TD error history}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, boxrule=.5pt, size=fbox, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{22}{\hspace{3.5pt}}
\begin{Verbatim}[commandchars=\\\{\}]
Text(0.5, 1.0, 'TD error history')
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_10_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{separate-plastic-weights-for-go-no-go}{%
\subsection{Separate plastic weights for go \& no
go}\label{separate-plastic-weights-for-go-no-go}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{23}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}This spiking reservoir network class includes 2 sets of plastic readout }
\PY{l+s+sd}{(output) weights.  One set of weights corresponds to go, and the other to nogo.}
\PY{l+s+sd}{They are not constrained to be either fully positive or fully negative.\PYZsq{}\PYZsq{}\PYZsq{}}
\PY{k}{class} \PY{n+nc}{SpikingReservoir\PYZus{}v2}\PY{p}{(}\PY{n}{SpikingReservoir\PYZus{}v1}\PY{p}{)}\PY{p}{:}

  \PY{k}{def} \PY{n+nf}{init\PYZus{}output\PYZus{}weights}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{nodes}\PY{p}{,} \PY{n}{output\PYZus{}dim}\PY{p}{)}\PY{p}{:}
    \PY{n}{W\PYZus{}go} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{p}{(}\PY{n}{nodes}\PY{p}{,} \PY{n}{output\PYZus{}dim}\PY{p}{)}\PY{p}{)}
    \PY{n}{W\PYZus{}nogo} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{p}{(}\PY{n}{nodes}\PY{p}{,} \PY{n}{output\PYZus{}dim}\PY{p}{)}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} According to the paper: normalize according to the squared sum of the weights for each output node.}
    \PY{n}{W\PYZus{}go} \PY{o}{/}\PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{norm}\PY{p}{(}\PY{n}{W\PYZus{}go}\PY{p}{)}
    \PY{n}{W\PYZus{}nogo} \PY{o}{/}\PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{norm}\PY{p}{(}\PY{n}{W\PYZus{}nogo}\PY{p}{)}

    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{go\PYZus{}weights} \PY{o}{=} \PY{n}{W\PYZus{}go}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{nogo\PYZus{}weights} \PY{o}{=} \PY{n}{W\PYZus{}nogo}

  \PY{k}{def} \PY{n+nf}{step}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{I}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}\PY{p}{:}
    \PY{k}{if} \PY{n}{np}\PY{o}{.}\PY{n}{array\PYZus{}equal}\PY{p}{(}\PY{n}{I}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{:}
        \PY{n}{I} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}input}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}

    \PY{n}{tau} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tau}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
    \PY{n}{dt} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
    \PY{n}{g} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{network gain}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
    \PY{n}{sigma\PYZus{}noise} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{noise gain}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
    \PY{n}{y\PYZus{}0} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{base firing rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
    \PY{n}{y\PYZus{}max} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max firing rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}

    \PY{n}{white\PYZus{}noise} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{randint}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{high}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x}\PY{o}{.}\PY{n}{size}\PY{p}{)}

    \PY{n}{dx\PYZus{}dt} \PY{o}{=} \PY{l+m+mi}{1}\PY{o}{/}\PY{n}{tau} \PY{o}{*} \PY{p}{(}\PY{o}{\PYZhy{}}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x} \PY{o}{+} \PY{n}{g} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{hidden\PYZus{}weights}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{y}\PY{p}{)} 
                     \PY{o}{+} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}input}\PY{o}{.}\PY{n}{T}\PY{p}{,} \PY{n}{I}\PY{p}{)} 
                     \PY{o}{+} \PY{n}{sigma\PYZus{}noise} \PY{o}{*} \PY{n}{white\PYZus{}noise}\PY{p}{)}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x} \PY{o}{+}\PY{o}{=} \PY{n}{dx\PYZus{}dt} \PY{o}{*} \PY{n}{dt}

    \PY{n}{y\PYZus{}conditions} \PY{o}{=}\PY{p}{[}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{l+m+mi}{0}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x} \PY{o}{\PYZgt{}} \PY{l+m+mi}{0}\PY{p}{]}
    \PY{n}{y\PYZus{}functions} \PY{o}{=}\PY{p}{[}
        \PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{y\PYZus{}0} \PY{o}{+} \PY{n}{y\PYZus{}0} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{tanh}\PY{p}{(}\PY{n}{x}\PY{o}{/}\PY{n}{y\PYZus{}0}\PY{p}{)}\PY{p}{,}
        \PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{y\PYZus{}0} \PY{o}{+} \PY{p}{(}\PY{n}{y\PYZus{}max} \PY{o}{\PYZhy{}} \PY{n}{y\PYZus{}0}\PY{p}{)} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{tanh}\PY{p}{(}\PY{n}{x}\PY{o}{/}\PY{p}{(}\PY{n}{y\PYZus{}max} \PY{o}{\PYZhy{}} \PY{n}{y\PYZus{}0}\PY{p}{)}\PY{p}{)}
    \PY{p}{]}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{piecewise}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x}\PY{p}{,} \PY{n}{y\PYZus{}conditions}\PY{p}{,} \PY{n}{y\PYZus{}functions}\PY{p}{)}

    \PY{n}{v} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{y}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{go\PYZus{}weights}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{y}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{nogo\PYZus{}weights}\PY{p}{)}
    \PY{n}{p} \PY{o}{=} \PY{n}{sigmoid\PYZus{}avg}\PY{p}{(}\PY{n}{v}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{exp\PYZus{}r} \PY{o}{=} \PY{n}{p}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{z} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{p}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{1}\PY{o}{\PYZhy{}}\PY{n}{p}\PY{p}{,} \PY{n}{p}\PY{p}{]}\PY{p}{)}

    \PY{k}{return} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{z}

  \PY{k}{def} \PY{n+nf}{receive\PYZus{}reward}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{r}\PY{p}{)}\PY{p}{:}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{p}{)}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{update\PYZus{}weights}\PY{p}{(}\PY{n}{r}\PY{p}{)}
  
  \PY{k}{def} \PY{n+nf}{update\PYZus{}weights}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{r}\PY{p}{)}\PY{p}{:}
    \PY{k}{if} \PY{n}{r} \PY{o}{==} \PY{l+m+mi}{1}\PY{p}{:}
      \PY{n}{delta\PYZus{}w} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{learning rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{outer}\PY{p}{(}\PY{p}{(}\PY{n}{r} \PY{o}{\PYZhy{}} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{exp\PYZus{}r}\PY{p}{)}\PY{p}{,}
              \PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{y} \PY{o}{\PYZhy{}} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{training threshold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
      \PY{n}{delta\PYZus{}w} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{multiply}\PY{p}{(}\PY{n}{delta\PYZus{}w}\PY{o}{.}\PY{n}{T}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{z}\PY{p}{)}
      \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{go\PYZus{}weights} \PY{o}{\PYZhy{}}\PY{o}{=} \PY{n}{delta\PYZus{}w}
      \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{go\PYZus{}weights} \PY{o}{/}\PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{norm}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{go\PYZus{}weights}\PY{p}{)}
    \PY{k}{elif} \PY{n}{r} \PY{o}{==} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{:}
      \PY{n}{delta\PYZus{}w} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{learning rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{outer}\PY{p}{(}\PY{p}{(}\PY{n}{r} \PY{o}{\PYZhy{}} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{exp\PYZus{}r}\PY{p}{)}\PY{p}{,}
               \PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{y} \PY{o}{\PYZhy{}} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{training threshold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
      \PY{n}{delta\PYZus{}w} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{multiply}\PY{p}{(}\PY{n}{delta\PYZus{}w}\PY{o}{.}\PY{n}{T}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{z}\PY{p}{)}
      \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{nogo\PYZus{}weights} \PY{o}{+}\PY{o}{=} \PY{n}{delta\PYZus{}w}
      \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{nogo\PYZus{}weights} \PY{o}{/}\PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{norm}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{nogo\PYZus{}weights}\PY{p}{)}
  
  \PY{k}{def} \PY{n+nf}{get\PYZus{}output}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{exp}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{:}
    \PY{k}{if} \PY{n}{exp}\PY{p}{:}
        \PY{k}{return} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{z}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{exp\PYZus{}r}
    \PY{k}{else}\PY{p}{:}
        \PY{k}{return} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{z}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{24}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{net} \PY{o}{=} \PY{n}{SpikingReservoir\PYZus{}v2}\PY{p}{(}\PY{l+m+mi}{500}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{n}{reservoir\PYZus{}network\PYZus{}params}\PY{p}{)}
\PY{n}{r\PYZus{}hist}\PY{p}{,} \PY{n}{decision\PYZus{}hist}\PY{p}{,} \PY{n}{exp\PYZus{}hist} \PY{o}{=} \PY{n}{simple\PYZus{}experiment}\PY{p}{(}\PY{n}{T}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{,} \PY{n}{num\PYZus{}trials}\PY{o}{=}\PY{l+m+mi}{300}\PY{p}{,} 
                              \PY{n}{net}\PY{o}{=}\PY{n}{net}\PY{p}{,} \PY{n}{I}\PY{o}{=}\PY{n}{I}\PY{p}{,} \PY{n}{contingency}\PY{o}{=}\PY{n}{I2A\PYZus{}1}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{25}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Smoothen the reward history curve.}
\PY{n}{time\PYZus{}filtered} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{r\PYZus{}hist}\PY{o}{.}\PY{n}{size}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}
\PY{n}{r\PYZus{}filtered} \PY{o}{=} \PY{n}{smooth}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{n}{r\PYZus{}hist}\PY{o}{.}\PY{n}{size}\PY{p}{)}\PY{p}{,} \PY{n}{time\PYZus{}filtered}\PY{p}{,} \PY{n}{r\PYZus{}hist}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Calculate TD error history.}
\PY{n}{td\PYZus{}hist} \PY{o}{=} \PY{n}{r\PYZus{}hist} \PY{o}{\PYZhy{}} \PY{n}{np}\PY{o}{.}\PY{n}{multiply}\PY{p}{(}\PY{n}{exp\PYZus{}hist}\PY{p}{,} \PY{n}{decision\PYZus{}hist}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{26}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Plot.}
\PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{nrows} \PY{o}{=} \PY{l+m+mi}{4}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{4}\PY{o}{*}\PY{l+m+mi}{4}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{r\PYZus{}hist}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{time\PYZus{}filtered}\PY{p}{,} \PY{n}{r\PYZus{}filtered}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{decision\PYZus{}hist}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{exp\PYZus{}hist}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{td\PYZus{}hist}\PY{p}{)}

\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{reward applied (+ smoothening)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{decision history}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{expectation history}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TD error history}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, boxrule=.5pt, size=fbox, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{26}{\hspace{3.5pt}}
\begin{Verbatim}[commandchars=\\\{\}]
Text(0.5, 1.0, 'TD error history')
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_15_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{50}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{} This is a very naive implementation of the separate go / nogo pathways.}
\PY{l+s+sd}{It creates 1 excitatory and 1 inhibitory reservoir that are connected }
\PY{l+s+sd}{to each other.  More refinement will be needed.\PYZsq{}\PYZsq{}\PYZsq{}}

\PY{k}{class} \PY{n+nc}{SpikingReservoir\PYZus{}v3}\PY{p}{(}\PY{n}{SpikingReservoir\PYZus{}v1}\PY{p}{)}\PY{p}{:}
  \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{nodes}\PY{p}{,} \PY{n}{input\PYZus{}dim}\PY{p}{,} \PY{n}{params}\PY{p}{,} \PY{n}{output\PYZus{}dim}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{sparse}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{:}
    \PY{n+nb}{super}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n+nf+fm}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n}{nodes}\PY{p}{,} \PY{n}{input\PYZus{}dim}\PY{p}{,} \PY{n}{params}\PY{p}{,} \PY{n}{output\PYZus{}dim}\PY{p}{,} \PY{n}{sparse}\PY{p}{)}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{nodes}\PY{p}{)}\PY{p}{)}
    
  \PY{k}{def} \PY{n+nf}{init\PYZus{}neurons}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{nodes}\PY{p}{)}\PY{p}{:}
    \PY{n}{std\PYZus{}dev} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{initial noise gain}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{c+c1}{\PYZsh{} The paper uses a variance of sigma\PYZus{}ini\PYZca{}2}
    \PY{n}{x\PYZus{}exc} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{std\PYZus{}dev}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n}{nodes}\PY{p}{)}
    \PY{n}{x\PYZus{}inh} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{std\PYZus{}dev}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n}{nodes}\PY{p}{)}
    
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{x\PYZus{}exc}\PY{p}{,} \PY{n}{x\PYZus{}inh}\PY{p}{]}\PY{p}{)}
  \PY{k}{def} \PY{n+nf}{init\PYZus{}output\PYZus{}weights}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{nodes}\PY{p}{,} \PY{n}{output\PYZus{}dim}\PY{p}{)}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} Readout weights from each reservoir.}
        
    \PY{n}{w\PYZus{}exc\PYZus{}go} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{p}{(}\PY{n}{nodes}\PY{p}{,} \PY{n}{output\PYZus{}dim}\PY{p}{)}\PY{p}{)}
    \PY{n}{w\PYZus{}inh\PYZus{}go} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{p}{(}\PY{n}{nodes}\PY{p}{,} \PY{n}{output\PYZus{}dim}\PY{p}{)}\PY{p}{)}
    \PY{n}{w\PYZus{}exc\PYZus{}nogo} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{p}{(}\PY{n}{nodes}\PY{p}{,} \PY{n}{output\PYZus{}dim}\PY{p}{)}\PY{p}{)}
    \PY{n}{w\PYZus{}inh\PYZus{}nogo} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{p}{(}\PY{n}{nodes}\PY{p}{,} \PY{n}{output\PYZus{}dim}\PY{p}{)}\PY{p}{)}

    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}exc\PYZus{}go} \PY{o}{=} \PY{n}{w\PYZus{}exc\PYZus{}go}  
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}inh\PYZus{}go} \PY{o}{=} \PY{n}{w\PYZus{}inh\PYZus{}go}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}exc\PYZus{}nogo} \PY{o}{=} \PY{n}{w\PYZus{}exc\PYZus{}nogo}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}inh\PYZus{}nogo} \PY{o}{=} \PY{n}{w\PYZus{}inh\PYZus{}nogo}
  
  \PY{k}{def} \PY{n+nf}{init\PYZus{}hidden\PYZus{}weights}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{nodes}\PY{p}{)}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} Recursive weights for reservoir feedback.}
    \PY{n}{g} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{initial noise gain}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
    \PY{n}{p} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hidden layer prob}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
    \PY{n}{std\PYZus{}dev} \PY{o}{=} \PY{n}{g} \PY{o}{/} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n}{p} \PY{o}{*} \PY{n}{nodes}\PY{p}{)} \PY{c+c1}{\PYZsh{} The paper uses a variance of g\PYZca{}2/(p*N)}

    \PY{n}{w\PYZus{}exc\PYZus{}exc} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{std\PYZus{}dev}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{p}{(}\PY{n}{nodes}\PY{p}{,} \PY{n}{nodes}\PY{p}{)}\PY{p}{)}
    \PY{n}{w\PYZus{}exc\PYZus{}inh} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{std\PYZus{}dev}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{p}{(}\PY{n}{nodes}\PY{p}{,} \PY{n}{nodes}\PY{p}{)}\PY{p}{)}
    \PY{n}{w\PYZus{}inh\PYZus{}exc} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{std\PYZus{}dev}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{p}{(}\PY{n}{nodes}\PY{p}{,} \PY{n}{nodes}\PY{p}{)}\PY{p}{)}

    \PY{n}{W} \PY{o}{=} \PY{p}{[}\PY{n}{w\PYZus{}exc\PYZus{}exc}\PY{p}{,} \PY{n}{w\PYZus{}exc\PYZus{}inh}\PY{p}{,} \PY{n}{w\PYZus{}inh\PYZus{}exc}\PY{p}{]}
    \PY{k}{if} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{sparse}\PY{p}{:}
      \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{W}\PY{p}{)}\PY{p}{)}\PY{p}{:}
        \PY{n}{indices} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n}{W}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{o}{.}\PY{n}{shape}\PY{p}{,} \PY{n}{p}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{p}\PY{p}{,} \PY{n}{p}\PY{p}{]}\PY{p}{)}
        \PY{n}{W}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{multiply}\PY{p}{(}\PY{n}{W}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,} \PY{n}{indices}\PY{p}{)}
    
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}exc\PYZus{}exc} \PY{o}{=} \PY{n}{w\PYZus{}exc\PYZus{}exc}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}exc\PYZus{}inh} \PY{o}{=} \PY{n}{w\PYZus{}exc\PYZus{}inh}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}inh\PYZus{}exc} \PY{o}{=} \PY{n}{w\PYZus{}inh\PYZus{}exc}
  
  \PY{k}{def} \PY{n+nf}{step}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{I}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}\PY{p}{:}
    \PY{k}{if} \PY{n}{np}\PY{o}{.}\PY{n}{array\PYZus{}equal}\PY{p}{(}\PY{n}{I}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{:}
        \PY{n}{I} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}input}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Parameter specifications.}
    \PY{n}{tau} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tau}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
    \PY{n}{dt} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
    \PY{n}{g} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{network gain}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
    \PY{n}{sigma\PYZus{}noise} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{noise gain}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
    \PY{n}{y\PYZus{}0} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{base firing rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
    \PY{n}{y\PYZus{}max} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max firing rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}

    \PY{n}{white\PYZus{}noise} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{randint}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{high}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Reservoir interactions.}
    \PY{n}{dx\PYZus{}dt\PYZus{}exc} \PY{o}{=} \PY{l+m+mi}{1}\PY{o}{/}\PY{n}{tau} \PY{o}{*} \PY{p}{(}\PY{o}{\PYZhy{}}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PYZbs{}
                         \PY{o}{+} \PY{n}{g} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}exc\PYZus{}exc}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)} \PYZbs{}
                         \PY{o}{\PYZhy{}} \PY{n}{g} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}inh\PYZus{}exc}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
                         \PY{o}{+} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}input}\PY{o}{.}\PY{n}{T}\PY{p}{,} \PY{n}{I}\PY{p}{)}  \PYZbs{}
                         \PY{o}{+} \PY{n}{sigma\PYZus{}noise} \PY{o}{*} \PY{n}{white\PYZus{}noise}\PY{p}{)}
    
    \PY{n}{dx\PYZus{}dt\PYZus{}inh} \PY{o}{=} \PY{l+m+mi}{1}\PY{o}{/}\PY{n}{tau} \PY{o}{*} \PY{p}{(}\PY{o}{\PYZhy{}}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PYZbs{}
                         \PY{o}{+} \PY{n}{g} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}exc\PYZus{}inh}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)} \PYZbs{}
                         \PY{o}{+} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}input}\PY{o}{.}\PY{n}{T}\PY{p}{,} \PY{n}{I}\PY{p}{)}  \PYZbs{}
                         \PY{o}{+} \PY{n}{sigma\PYZus{}noise} \PY{o}{*} \PY{n}{white\PYZus{}noise}\PY{p}{)}
    
    
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{+}\PY{o}{=} \PY{n}{dx\PYZus{}dt\PYZus{}exc} \PY{o}{*} \PY{n}{dt}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{+}\PY{o}{=} \PY{n}{dx\PYZus{}dt\PYZus{}inh} \PY{o}{*} \PY{n}{dt}
    
    \PY{c+c1}{\PYZsh{} Reservoir neurons firing rate.}
    
    \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{p}{:}
      \PY{n}{y\PYZus{}conditions} \PY{o}{=} \PY{p}{[}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{l+m+mi}{0}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{\PYZgt{}} \PY{l+m+mi}{0}\PY{p}{]}
      \PY{n}{y\PYZus{}functions} \PY{o}{=}\PY{p}{[}
          \PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{y\PYZus{}0} \PY{o}{+} \PY{n}{y\PYZus{}0} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{tanh}\PY{p}{(}\PY{n}{x}\PY{o}{/}\PY{n}{y\PYZus{}0}\PY{p}{)}\PY{p}{,}
          \PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{y\PYZus{}0} \PY{o}{+} \PY{p}{(}\PY{n}{y\PYZus{}max} \PY{o}{\PYZhy{}} \PY{n}{y\PYZus{}0}\PY{p}{)} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{tanh}\PY{p}{(}\PY{n}{x}\PY{o}{/}\PY{p}{(}\PY{n}{y\PYZus{}max} \PY{o}{\PYZhy{}} \PY{n}{y\PYZus{}0}\PY{p}{)}\PY{p}{)}
      \PY{p}{]}
      \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{y}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{piecewise}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{x}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,} \PY{n}{y\PYZus{}conditions}\PY{p}{,} \PY{n}{y\PYZus{}functions}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} TODO: Vectorize the above loop: y = firing\PYZus{}rate(x).}
    \PY{c+c1}{\PYZsh{} TODO: Vectorize the output weights: v = W*y.}
    
    \PY{c+c1}{\PYZsh{} TODO: This entire output sequence needs to be revised.}
    \PY{c+c1}{\PYZsh{} TODO: Revise interactions between exc and inh reservoirs}
    \PY{c+c1}{\PYZsh{} and the output.}
    \PY{n}{v\PYZus{}go} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{y}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}exc\PYZus{}go}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{y}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}inh\PYZus{}go}\PY{p}{)}
    \PY{n}{v\PYZus{}nogo}\PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{y}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}exc\PYZus{}nogo}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{y}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}inh\PYZus{}nogo}\PY{p}{)}
    \PY{n}{v} \PY{o}{=} \PY{n}{v\PYZus{}go} \PY{o}{\PYZhy{}} \PY{n}{v\PYZus{}nogo} 
    \PY{n}{p} \PY{o}{=} \PY{n}{sigmoid\PYZus{}avg}\PY{p}{(}\PY{n}{v}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{exp\PYZus{}r} \PY{o}{=} \PY{n}{p}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{z} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{p}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{1}\PY{o}{\PYZhy{}}\PY{n}{p}\PY{p}{,} \PY{n}{p}\PY{p}{]}\PY{p}{)}
    
  \PY{k}{def} \PY{n+nf}{receive\PYZus{}reward}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{r}\PY{p}{)}\PY{p}{:}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{p}{)}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{update\PYZus{}weights}\PY{p}{(}\PY{n}{r}\PY{p}{)}
  
  \PY{k}{def} \PY{n+nf}{update\PYZus{}weights}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{r}\PY{p}{)}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} TODO: Excitatory and inhibitory weights need to have different learning}
    \PY{c+c1}{\PYZsh{} rules.  Their update interactions also need to be clarified.}
    \PY{k}{if} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{z}\PY{p}{:}
      \PY{n}{delta\PYZus{}w} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{learning rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{outer}\PY{p}{(}\PY{p}{(}\PY{n}{r} \PY{o}{\PYZhy{}} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{exp\PYZus{}r}\PY{p}{)}\PY{p}{,}
              \PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{y}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{\PYZhy{}} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{training threshold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
      \PY{n}{delta\PYZus{}w} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{multiply}\PY{p}{(}\PY{n}{delta\PYZus{}w}\PY{o}{.}\PY{n}{T}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{z}\PY{p}{)}
      \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}exc\PYZus{}go} \PY{o}{\PYZhy{}}\PY{o}{=} \PY{n}{delta\PYZus{}w}
      \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}exc\PYZus{}go} \PY{o}{/}\PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{norm}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}exc\PYZus{}go}\PY{p}{)}
    \PY{k}{else}\PY{p}{:}
      \PY{n}{delta\PYZus{}w} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{learning rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{outer}\PY{p}{(}\PY{p}{(}\PY{n}{r} \PY{o}{\PYZhy{}} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{exp\PYZus{}r}\PY{p}{)}\PY{p}{,}
               \PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{y}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{\PYZhy{}} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{training threshold}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
      \PY{n}{delta\PYZus{}w} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{multiply}\PY{p}{(}\PY{n}{delta\PYZus{}w}\PY{o}{.}\PY{n}{T}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{z}\PY{p}{)}
      \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}inh\PYZus{}go} \PY{o}{\PYZhy{}}\PY{o}{=} \PY{n}{delta\PYZus{}w}
      \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}inh\PYZus{}go} \PY{o}{/}\PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{norm}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{w\PYZus{}inh\PYZus{}go}\PY{p}{)}
    \PY{c+c1}{\PYZsh{}self.output\PYZus{}weights = (self.output\PYZus{}weights + delta\PYZus{}w).clip(min=0)}
    
    \PY{c+c1}{\PYZsh{} Normalize weights}
    \PY{c+c1}{\PYZsh{}self.output\PYZus{}weights /= np.linalg.norm(self.output\PYZus{}weights)}

    \PY{k}{return} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{z}
    
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{51}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{net} \PY{o}{=} \PY{n}{SpikingReservoir\PYZus{}v3}\PY{p}{(}\PY{l+m+mi}{500}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{n}{reservoir\PYZus{}network\PYZus{}params}\PY{p}{)}
\PY{n}{r\PYZus{}hist}\PY{p}{,} \PY{n}{decision\PYZus{}hist}\PY{p}{,} \PY{n}{exp\PYZus{}hist} \PY{o}{=} \PY{n}{simple\PYZus{}experiment}\PY{p}{(}\PY{n}{T}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{,} \PY{n}{num\PYZus{}trials}\PY{o}{=}\PY{l+m+mi}{300}\PY{p}{,} 
                              \PY{n}{net}\PY{o}{=}\PY{n}{net}\PY{p}{,} \PY{n}{I}\PY{o}{=}\PY{n}{I}\PY{p}{,} \PY{n}{contingency}\PY{o}{=}\PY{n}{I2A\PYZus{}1}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{52}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Smoothen the reward history curve.}
\PY{n}{time\PYZus{}filtered} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{r\PYZus{}hist}\PY{o}{.}\PY{n}{size}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}
\PY{n}{r\PYZus{}filtered} \PY{o}{=} \PY{n}{smooth}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{n}{r\PYZus{}hist}\PY{o}{.}\PY{n}{size}\PY{p}{)}\PY{p}{,} \PY{n}{time\PYZus{}filtered}\PY{p}{,} \PY{n}{r\PYZus{}hist}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Calculate TD error history.}
\PY{n}{td\PYZus{}hist} \PY{o}{=} \PY{n}{r\PYZus{}hist} \PY{o}{\PYZhy{}} \PY{n}{np}\PY{o}{.}\PY{n}{multiply}\PY{p}{(}\PY{n}{exp\PYZus{}hist}\PY{p}{,} \PY{n}{decision\PYZus{}hist}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{53}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Plot.}
\PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{nrows} \PY{o}{=} \PY{l+m+mi}{4}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{4}\PY{o}{*}\PY{l+m+mi}{4}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{r\PYZus{}hist}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{time\PYZus{}filtered}\PY{p}{,} \PY{n}{r\PYZus{}filtered}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{decision\PYZus{}hist}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{exp\PYZus{}hist}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{td\PYZus{}hist}\PY{p}{)}

\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{reward applied (+ smoothening)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{decision history}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{expectation history}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TD error history}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, boxrule=.5pt, size=fbox, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{53}{\hspace{3.5pt}}
\begin{Verbatim}[commandchars=\\\{\}]
Text(0.5, 1.0, 'TD error history')
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_19_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]

\end{Verbatim}
\end{tcolorbox}


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
